# -*- coding: utf-8 -*-
"""LTV_python_code.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ARq9u_sqcfEgJzo57-exVZ_gWXTe660X
"""

from google.colab import files
uploaded = files.upload()

import pandas as pd

# Load files into DataFrames
orders = pd.read_csv("olist_orders_dataset.csv", parse_dates=["order_purchase_timestamp"])
order_items = pd.read_csv("olist_order_items_dataset.csv")
customers = pd.read_csv("olist_customers_dataset.csv")
products = pd.read_csv("olist_products_dataset.csv")
categories = pd.read_csv("product_category_name_translation.csv")

products = products.merge(categories, on="product_category_name", how="left")

order_items = order_items.merge(
    products[["product_id", "product_category_name_english"]],
    on="product_id",
    how="left"
)

orders = orders.merge(customers[["customer_id", "customer_unique_id"]], on="customer_id", how="left")

order_data = orders.merge(order_items, on="order_id", how="inner")

rfm = order_data.groupby("customer_unique_id").agg(
    total_orders=("order_id", "nunique"),
    total_items=("order_item_id", "count"),
    total_spent=("price", "sum"),
    avg_order_value=("price", "mean"),
    first_order_date=("order_purchase_timestamp", "min"),
    last_order_date=("order_purchase_timestamp", "max"),
    product_categories=("product_category_name_english", lambda x: list(set(x.dropna())))
).reset_index()

latest_date = order_data["order_purchase_timestamp"].max()
rfm["recency_days"] = (latest_date - rfm["last_order_date"]).dt.days

rfm.head()

rfm.to_csv("customer_rfm_dataset.csv", index=False)

import matplotlib.pyplot as plt
import seaborn as sns

sns.set(style="whitegrid")

fig, axs = plt.subplots(2, 2, figsize=(14, 10))
fig.suptitle("Customer Behavior Distributions", fontsize=16)

# Total Spent
axs[0, 0].hist(rfm["total_spent"], bins=50, color='skyblue', edgecolor='black')
axs[0, 0].set_title("Distribution of Total Spent")
axs[0, 0].set_xlabel("Total Spent (BRL)")
axs[0, 0].set_ylabel("Number of Customers")
axs[0, 0].set_xlim(0, 2000)

# Recency
axs[0, 1].hist(rfm["recency_days"], bins=50, color='lightgreen', edgecolor='black')
axs[0, 1].set_title("Customer Recency (Days Since Last Order)")
axs[0, 1].set_xlabel("Days")
axs[0, 1].set_ylabel("Number of Customers")

# Avg Order Value
axs[1, 0].boxplot(rfm["avg_order_value"].dropna(), vert=False)
axs[1, 0].set_title("Boxplot of Avg. Order Value")
axs[1, 0].set_xlabel("Average Order Value (BRL)")

# Total Orders
axs[1, 1].hist(rfm["total_orders"], bins=30, color='salmon', edgecolor='black')
axs[1, 1].set_title("Number of Orders per Customer")
axs[1, 1].set_xlabel("Total Orders")
axs[1, 1].set_ylabel("Customer Count")

plt.tight_layout(rect=[0, 0, 1, 0.96])
plt.show()

# Top 10 customers by total spent
rfm.sort_values("total_spent", ascending=False).head(10)

# Set cutoff date to split data into history vs future
cutoff_date = pd.to_datetime("2018-06-01")

# Split orders into past (features) and future (labels)
past_orders = order_data[order_data["order_purchase_timestamp"] < cutoff_date]
future_orders = order_data[order_data["order_purchase_timestamp"] >= cutoff_date]

# RFM features from past data
past_rfm = past_orders.groupby("customer_unique_id").agg(
    recency_days=("order_purchase_timestamp", lambda x: (cutoff_date - x.max()).days),
    frequency=("order_id", "nunique"),
    monetary=("price", "sum"),
    avg_order_value=("price", "mean")
).reset_index()

# Future revenue = label
future_ltv = future_orders.groupby("customer_unique_id").agg(
    future_ltv=("price", "sum")
).reset_index()

# Join features with target
ltv_dataset = past_rfm.merge(future_ltv, on="customer_unique_id", how="left")

# Fill missing LTVs with 0 (means they churned)
ltv_dataset["future_ltv"] = ltv_dataset["future_ltv"].fillna(0)

ltv_dataset.head()

from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error
from xgboost import XGBRegressor
import numpy as np

# Drop customer_id column for modeling
X = ltv_dataset.drop(columns=["customer_unique_id", "future_ltv"])
y = ltv_dataset["future_ltv"]

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# Initialize and train model
model = XGBRegressor(
    n_estimators=100,
    learning_rate=0.1,
    max_depth=4,
    random_state=42
)
model.fit(X_train, y_train)

# Make predictions
y_pred = model.predict(X_test)

# Evaluate the model
mae = mean_absolute_error(y_test, y_pred)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))

print(f"MAE (Mean Absolute Error): {mae:.2f}")
print(f"RMSE (Root Mean Squared Error): {rmse:.2f}")

import matplotlib.pyplot as plt

# Plot feature importance
plt.figure(figsize=(8, 5))
plt.bar(X.columns, model.feature_importances_)
plt.title("Feature Importance in LTV Prediction")
plt.xticks(rotation=45)
plt.show()

import pandas as pd
import numpy as np
from google.colab import files

# If kernel was reset, re-upload files
uploaded = files.upload()

# Load files
orders = pd.read_csv("olist_orders_dataset.csv", parse_dates=["order_purchase_timestamp"])
order_items = pd.read_csv("olist_order_items_dataset.csv")
customers = pd.read_csv("olist_customers_dataset.csv")
products = pd.read_csv("olist_products_dataset.csv")
categories = pd.read_csv("product_category_name_translation.csv")

products = products.merge(categories, on="product_category_name", how="left")

order_items = order_items.merge(
    products[["product_id", "product_category_name_english"]],
    on="product_id",
    how="left"
)

orders = orders.merge(customers[["customer_id", "customer_unique_id"]], on="customer_id", how="left")

order_data = orders.merge(order_items, on="order_id", how="inner")

cutoff_date = pd.to_datetime("2018-06-01")

past_orders = order_data[order_data["order_purchase_timestamp"] < cutoff_date]
future_orders = order_data[order_data["order_purchase_timestamp"] >= cutoff_date]

past_rfm = past_orders.groupby("customer_unique_id").agg(
    recency_days=("order_purchase_timestamp", lambda x: (cutoff_date - x.max()).days),
    frequency=("order_id", "nunique"),
    monetary=("price", "sum"),
    avg_order_value=("price", "mean")
).reset_index()

future_ltv = future_orders.groupby("customer_unique_id").agg(
    future_ltv=("price", "sum")
).reset_index()

ltv_dataset = past_rfm.merge(future_ltv, on="customer_unique_id", how="left")
ltv_dataset["future_ltv"] = ltv_dataset["future_ltv"].fillna(0)

# Simulate CAC and assign channels
channels = ['facebook', 'google', 'email', 'organic', 'referral']
cac_data = pd.DataFrame({
    'channel': channels,
    'cac': [12, 15, 5, 1, 3]
})
np.random.seed(42)
ltv_dataset["channel"] = np.random.choice(channels, size=len(ltv_dataset))
ltv_dataset = ltv_dataset.merge(cac_data, on="channel", how="left")

# Recalculate if necessary
ltv_dataset["ltv_cac_ratio"] = ltv_dataset["future_ltv"] / ltv_dataset["cac"]

# Replace infinite or NaN with 0
ltv_dataset["ltv_cac_ratio"] = ltv_dataset["ltv_cac_ratio"].replace([np.inf, -np.inf], np.nan)
ltv_dataset["ltv_cac_ratio"] = ltv_dataset["ltv_cac_ratio"].fillna(0)

def tag_segment(row):
    if row["ltv_cac_ratio"] >= 3:
        return "High ROI"
    elif row["ltv_cac_ratio"] >= 1:
        return "Break Even"
    else:
        return "Low ROI"

ltv_dataset["roi_segment"] = ltv_dataset.apply(tag_segment, axis=1)

# Create margin: profit per customer
ltv_dataset["margin"] = ltv_dataset["future_ltv"] - ltv_dataset["cac"]

roi_summary = ltv_dataset.groupby("roi_segment").agg(
    avg_ltv=("future_ltv", "mean"),
    avg_cac=("cac", "mean"),
    avg_margin=("margin", "mean"),
    customer_count=("customer_unique_id", "count")
).sort_values("avg_ltv", ascending=False)

pd.crosstab(ltv_dataset["channel"], ltv_dataset["roi_segment"], normalize='index') * 100

import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(10, 6))
sns.boxplot(data=ltv_dataset, x="channel", y="ltv_cac_ratio")
plt.title("LTV:CAC Ratio by Channel")
plt.xticks(rotation=45)
plt.axhline(1, color='red', linestyle='--', label="Break-even")
plt.axhline(3, color='green', linestyle='--', label="Target ROI")
plt.legend()
plt.show()

ltv_dataset.to_csv("ltv_profitability_dataset.csv", index=False)

from google.colab import files
files.download("ltv_profitability_dataset.csv")

